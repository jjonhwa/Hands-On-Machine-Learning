{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter 1. 한눈에 보는 머신러닝.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOgOvYGKPWiWoSL/eYrkIFa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjonhwa/Hands-On-Machine-Learning/blob/main/Chapter_1_%ED%95%9C%EB%88%88%EC%97%90_%EB%B3%B4%EB%8A%94_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5S_HulWSxKk"
      },
      "source": [
        "# 1.1 머신러닝이란?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cHYD6XHS6_d"
      },
      "source": [
        "* 일반적 정의 : 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야\r\n",
        "* 공학적 정의 : 어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됬다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25WOGPvFV5DX"
      },
      "source": [
        "# 1.2 왜 머신러닝을 사용하는가?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC0WM-X2V7w4"
      },
      "source": [
        "* 전통적인 방법 : 규칙 + 데이터 >> 정답\r\n",
        "* 머신러닝 방법 : 정답 + 데이터 >> 규칙"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_FFtumnWQjV"
      },
      "source": [
        "머신러닝을 사용함으로서 얻을 수 있는 이점\r\n",
        "1. 전통적인 방식으로는 너무 복잡하거나 알려진 알고리즘이 없는 문제에 머신러닝이 유용하다(ex, 음성인식)\r\n",
        "2. 머신러닝을 통해 배울 수 있다. -- 머신러닝 알고르즘이 학습한 것을 조사함으로서 가끔 예상치 못한 연관 관계나 새로운 추세가 발견되기도 한다.(이를 **데이터 마이닝**이라고 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ59AvgQWzsR"
      },
      "source": [
        "머신러닝이 띄어난 분야\r\n",
        "1. 기존의 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제.\r\n",
        "2. 전통적인 방식으로는 해결방법이 없는 복잡한 문제.\r\n",
        "3. 유동적인 환경\r\n",
        "4. 복잡한 문제와 대량의 데이터에서 통찰을 얻고 싶은 경우"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FRLnWE2W9lx"
      },
      "source": [
        "# 1.3 애플리케이션 사례"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0qjfP-9XG5S"
      },
      "source": [
        "1. 생산 라인에서 제품 이미지를 자동으로 분류하기 : 이미지 분류(CNN)\r\n",
        "2. 뇌 스캔 - 종양 진단                           : 시맨틱 분할(CNN)\r\n",
        "3. 뉴스 기사 자동 분류                           : 자연어처리 - 텍스트분석(RNN, CNN, Transformer)\r\n",
        "4. 포럼 부정코멘트 자동 구분                     : 자연어처리 - 텍스트분석\r\n",
        "5. 긴 문서 자동 요약                             : 자연어처리 - 텍스트 요약\r\n",
        "6. 챗봇 만들기                                   : 자연어이해\r\n",
        "7. 회사 내년 수익 예측                           : 회귀(Linear Regression, Polynomial Regression, SVM, Random Forest, ANN + RNN, CNN, Transformer)\r\n",
        "8. 음성 명령에 반응하는 앱 개발                  : 음성 인식(RNN, CNN, Transformer)\r\n",
        "9. 신용 카드 부정 거래 감지                      : 이상치 탐지\r\n",
        "10. 구매 이력 기반 마케팅 전략 계획              : 군집분석(Clustering)\r\n",
        "11. 그래프 표현                                  : 데이터 시각화(PCA)\r\n",
        "12. 상품 추천                                    : 추천 시스템(ANN)\r\n",
        "13. 지능형 게임 봇 만들기                        : 강화학습(RL)\r\n",
        "14. etc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94FqtiMa7cI"
      },
      "source": [
        "# 1.4 머신러닝 시스템의 종류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLAsuTBqbFLk"
      },
      "source": [
        "* 감독하에 훈련하는 것인지 아닌지 : 지도, 비지도, 준지도, 강화학습\r\n",
        "* 실시간으로 점진적인 학습을 하는지 아닌지 : 온라인학습, 배치학습\r\n",
        "* 단순히 데이터 비교인지 혹은 패턴을 발견해 예측 모델을 만드는지 : 사례 기반 학습, 모델 기반 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsrCmQvubVu5"
      },
      "source": [
        "## 1.4.1 지도 학습과 비지도 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjyfOGWkbjj8"
      },
      "source": [
        "### **지도 학습**\r\n",
        "알고리즘에 주입하는 훈련 데이터에 레이블(정답)이 포함되어 있다.  \r\n",
        "\r\n",
        "* 분류 : 좋은 예로 스팸필터가 있으며, 어떻게 새 메일을 분류할지 학습한다.\r\n",
        "* 회귀 : feature를 사용해 target값을 예측  \r\n",
        "\r\n",
        "**지도 학습 알고리즘의 종류**\r\n",
        "1. K-nearest neighbors\r\n",
        "2. Linear Regression\r\n",
        "3. Logistic Regression\r\n",
        "4. SVM\r\n",
        "5. Decision Tree & Random Forest\r\n",
        "6. Neural Networks\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzS3U-QPdAPU"
      },
      "source": [
        "### **비지도 학습**\r\n",
        "훈련 데이터에 레이블(정답)이 없이 훈련한다.  \r\n",
        "\r\n",
        "**비지도 학습 알고리즘**\r\n",
        "1. 군집(Clustering)  \r\n",
        "- 비슷한 방문자들끼리 그룹으로 묶는다. 특히 HCA를 사용하면 각 그룹을 더 작은 그룹으로 세분화 할 수 있다.\r\n",
        "  - k-means\r\n",
        "  - DBSCAN\r\n",
        "  - 계층 군집 분석(HCA)\r\n",
        "  - 이상치 탐지 & 특이치 탐지(ex. 신용카드 부정거래)\r\n",
        "  - 원 클래스 SVM\r\n",
        "  - Isolation Forest\r\n",
        "2. 시각화와 차원 축소  \r\n",
        "- 레이블이 없는 고차원 데이터를 넣어 도식화가 가능항 2D나 3D로 표현한다. 이로써 데이터가 어떻게 조직되어있는지 이해할 수 있고 예상치 못한 패턴을 발견할 수도 있다.  \r\n",
        "- 차원 축소의 경우 너무 많은 정보를 잃지 않으면서 데이터를 간소화 하는 것이다.(머신러닝 알고리즘에 데이터를 주입하기 전 차원 축소를 하면 실행속도가 빨라지며 메모리 공간도 여유가 생기고 경우에 따라서는 성능이 좋아지기도 한다.)\r\n",
        "  - 주성분 분석(PCA)\r\n",
        "  - 커널 PCA\r\n",
        "  - 지역적 선형 임베딩(LLE)\r\n",
        "  - t-SNE\r\n",
        "3. 연관 규칙 학습(Association Rule Learning)  \r\n",
        "- feature들 간의 흥미로운 관계(ex, 바베큐 소스를 구매한 사람이 스테이크도 많이 구매한다! 그러므로 아마 이 두 상품을 가까이 진열하면 좋을 것이다.)\r\n",
        "  - Apriori\r\n",
        "  - Eclat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh1BEG42mvNs"
      },
      "source": [
        "### **준지도 학습**\r\n",
        "* 일부는 레이블이 존재하고 일부는 레이블이 존재하지 않는 알고리즘을 학습한다.\r\n",
        "\r\n",
        "  * ex) 구글 포토 호스팅 서비스 : 각 사람들이 어떤 사진에 있는지 군집 분석을 한 후. 그 사람이 누구인지 레이블링을 한다. 이로써 어떤 사진에 어떤 사람이 있는지 쉽게 알 수 있다.  \r\n",
        "\r\n",
        "* 대부분의 준지도 학습은 지도 학습과 비지도 학습의 조합으로 이루어져 있다.\r\n",
        "  * ex) DBN(심층 신뢰 신경망) : 여러 겹의 RBM(제한된 볼츠만 머신)으로 구성되어 있는데 이는 RBM이 비지도 학습으로 순차적 학습을 한 후 전체 시스템이 전체 지도 학습으로 세밀하게 조정한다.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7yq0lF0otwl"
      },
      "source": [
        "### **강화 학습**\r\n",
        "* 환경을 관찰해서 행동을 실행하고 그 결과로 보상을 받는다.\r\n",
        "* 보상을 얻기 위해 행해야 하는 정책을 스스로 학습하여 탐구한다.\r\n",
        "  * ex) 알파고 : 수백만 개의 게임을 분석해서 승리에 대한 전략을 학습한 후 학습 기능을 끄고 학습한 전략을 사용해 게임에 임한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3sXSdPVpS4f"
      },
      "source": [
        "## 1.4.2 배치 학습과 온라인 학습\r\n",
        "머신러닝 시스템을 분류하는 데 사용하는 다른 기준은 입력 데이터의 스트림부터 점진적으로 학습할 수 있는지 여부이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbqKxizyp4M4"
      },
      "source": [
        "### 배치 학습\r\n",
        "* 시스템이 점진적으로 학습할 수 없다.\r\n",
        "* 가용한 데이터를 모두 사용해 훈련해야 한다.\r\n",
        "* 시간과 자원을 많이 소모해 주로 오프라인에서 수행된다.\r\n",
        "* 시스템 훈련 후 적용하면 더 이상의 훈련 없이 실행된다(즉, 학습한 것을 적용만 한다 - 오프라인 학습)\r\n",
        "* 새로운 데이터를 학습하려면 전체 데이터를 사용하여 시스템의 새로운 버전을 처음부터 훈련해야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9rSoFXA1iz4"
      },
      "source": [
        "### 온라인 학습\r\n",
        "* 데이터를 순차적으로 한 개씩 또는 미니배치 단위로 시스템을 훈련시킨다.\r\n",
        "* 매 학습 단계가 빠르고 비용이 적어서 데이터가 도착하는 대로 즉시 학습할 수 있다.\r\n",
        "* 연속적으로 데이터를 받고 빠른 변화에 스스로 적응해야 하는 시스템에 적합하다.\r\n",
        "* Learning Rate : 변화하는 데이터에 얼마나 빠르게 적을 할 것인지를 나타내는 하이퍼파라미터로서 높게하면 빠르게 적응하지만 이전 데이터를 금방 잊어버리며 낮게하면 더 느리게 학습된다.\r\n",
        "* 온라인 학습에서의 가장 큰 문제점은 시스템에 나쁜 데이터가 주입되었을 때 시스템 성능이 점진적으로 감소한다는 점이다.(그러므로 위험을 줄이기 위해서 면밀히 모니터링을 해야한다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l58InI63YUa-"
      },
      "source": [
        "## 1.4.3 사례 기반 학습과 모델 기반 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzAqsxGgYZ34"
      },
      "source": [
        "어떻게 일반화 되는가에 따라서 사례 기반 학습과 모델 기반 학습으로 나눌 수 있다.  \r\n",
        "\r\n",
        "### 사례 기반 학습\r\n",
        "* 단순히 기억하는 학습이다.\r\n",
        "* 예를 들어, 스팸 메일 구분을 학습시킨다고 할 때 스팸 메일과 공통된 단어가 많을 경우 스펨으로 구분하도록 학습시키는 것이 사례 기반 학습이다.\r\n",
        "* 즉, 훈련 샘플을 기억함으로써 학습하는 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3lp90C6Zf1X"
      },
      "source": [
        "### 모델 기반 학습\r\n",
        "* 모델을 만들어 예측에 사용하는 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "On2rOm0Dj0vC"
      },
      "source": [
        "# 1.5 머신러닝의 주요 도전 과제\r\n",
        "우리가 여기서 알아볼 것은 데이터를 훈련시키는 데 있어서 문제가 될 수 있는 '나쁜 알고리즘'과 '나쁜 데이터'이다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtARpVyTkr_3"
      },
      "source": [
        "## 1.5.1 충분하지 않은 양의 훈련 데이터\r\n",
        "* 대부분의 머신러닝 알고리즘이 잘 작동하려면 데이터가 많아야한다.\r\n",
        "* 복잡한 문제에서는 알고리즘보다 데이터가 더 중요하다.\r\n",
        "* 현재까지 작거나 중간 규모의 데이터셋은 흔하고, 훈련 데이털르 추가로 모으는 것은 쉽지 않다. 즉, 아직까지는 알고리즘을 무시할 수 없다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyfEWFBylSFI"
      },
      "source": [
        "## 1.5.2 대표성이 없는 훈련 데이터\r\n",
        "* 일반화가 잘되려면 우리가 원하는 사례를 training data가 잘 대표해야 한다.\r\n",
        "* 샘플수가 작으면 sampling noise(우연에 의한 대표성 없는 데이터)가 발생할 수 있고, 샘플수가 크더라도 sampling bias(ex, 대통령 선거(관심있는 사람 및 당시 고위층))가 생길 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wqbabrUl7Jt"
      },
      "source": [
        "## 1.5.3 낮은 품질의 데이터\r\n",
        "데이터의 품질이 낮을 경우 다음과 같이 정제 해주어야 한다.\r\n",
        "* 이상치 발생시 무시 혹은 수동으로 수정한다.\r\n",
        "* NaN값이 있을 경우 그 feature를 무시할지 혹은 sample을 무시할지 혹은 매꿀지, 따로 훈련시킬지 등등으로 해결해주어야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVLkaCjcmtT9"
      },
      "source": [
        "## 1.5.4 관련 없는 특성\r\n",
        "Garbage In Garbage Out.  \r\n",
        "훈련에 관련 있는 특성이 많고 관련 없는 특성이 적어야 훈련이 잘 된다. 즉, 좋은 머신러닝 프로젝트의 핵심은 **좋은 특성(feature)**를 찾는 것이다.\r\n",
        "* 특성 선택 : 가지고 있는 특성 중에서 훈련에 가장 유용한 특성을 선택한다.\r\n",
        "* 특성 추출 : 특성을 결합하여 더 유용한 특성을 만든다.(ex, PCA)\r\n",
        "* 새로운 데이터 수집"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2J3e0lYnLyt"
      },
      "source": [
        "## 1.5.5 Overfitting\r\n",
        "모델이 Training Data에 지나치게 적합하여 일반성이 떨어지는 경우 Overfitting되었다고 한다.  \r\n",
        "다음과 같은 경우에 새로운 샘플에 일반화되지 못한다.\r\n",
        "* Training Set에 Noise가 많을 경우\r\n",
        "* Dataset이 작을 경우  \r\n",
        "\r\n",
        "Overfitting은 Training Data에 있는 Noise의 양에 비해 모델이 너무 복잡할 떄 일어난다.  \r\n",
        "다음은 Overfitting을 해결할 수 있는 방법이다.\r\n",
        "* 파라미터 수가 적은 모델 선택(고차원 다항 < 선형)\r\n",
        "* Training Set에서의 feature수를 줄인다.\r\n",
        "* Model에 restriction을 준다. - regularization\r\n",
        "* Training Data를 더 많이 수집한다.\r\n",
        "* Training Data에서의 Noise를 줄인다.\r\n",
        "\r\n",
        "-- 더불어 Regularization을 정하는 것은 Hyperparameter가 하는데, 이는 학습 알고리즘의 파라미터로서 알고리즘에 영향을 받지 않고, 미리 지정되며, 상수이다.(예를 들어, Learning Rate, Batch_size, epochs등이 있다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAdbpXCEpVes"
      },
      "source": [
        "## 1.5.6 Underfitting\r\n",
        "모델이 너무 단순애서 데이터의 내재된 구조를 학습하지 못할 때 일어난다.\r\n",
        "Underfitting을 해결할 수 있는 방법은 다음과 같다.\r\n",
        "* 모델 파라미터가 더 많은 모델을 선택한다.\r\n",
        "* 더 좋은 feature를 제공한다.\r\n",
        "* restrictiond을 적게 준다.(regularization을 작게한다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkLWkKnapv7G"
      },
      "source": [
        "# 1.6 테스트와 검증\r\n",
        "모델이 새로운 샘플에 얼마나 잘 일반화될지 아는 방법은 샘플에 실제로 적용해보는 것이다. 이를 간접적으로 알 수 있기 위해 샘플을 Training Set과 Test Set으로 나눈 후 Training Set으로 훈련 한 후 Test Set으로 테스트한다.(보통 총 Data의 80%를 Training, 20%를 Test로 사용한다. 이는 보통그러는 경우이며 다르게 설정해도 무관하다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlTHbQFDqh8H"
      },
      "source": [
        "* 홀드아웃 검증 : Training Set을 다시 Training과 Validation으로 나뉘어서 학습시킨 후 가장 좋은 모델을 Test Set에서 다시 평가하는 방법이다.\r\n",
        "* 교차 검증 : Validation Set 여러 개를 사용하여 평가한 후 이들의 평균을 구해서 사용하는 것이다. 다만 Validation Set의 개수에 비례하여 훈련시간이 늘어난다.\r\n",
        "\r\n",
        "\r\n",
        "* 데이터 불일치 :   \r\n",
        "잘못된 결과 나왔을 경우 그것이 데이터 불일치로부터 온 것인지 Overfit으로 부터 온것인지 모를 경우가 있다.   \r\n",
        "그럴 때 train, train-dev, dev set으로 나눈 후 train-dev에서 잘 작동하고 dev에서만 잘 작동하지 않는다면 이것은 데이터 불일치에서 오는 문제임을 알 수 있다. 반면, train-dev에서 잘 작동하지 않는다면 이것은 overfit의 문제이다.(ex, 웹 사진과 휴대폰으로 찍은 사진 - 데이터불일치로 인한 오류)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzTD09OdvGCH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}